{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Corpus \n",
    "\n",
    "positive = ['This is an excellent movie',\n",
    "             'The move was fantastic I like it',\n",
    "             'You should watch it is brilliant',\n",
    "             'Exceptionally good','Wonderfully directed and executed I like it',\n",
    "             'Its a fantastic series',\n",
    "             'Never watched such a brillent movie','It is a Wonderful movie']\n",
    "\n",
    "negative = [\"horrible acting\",\n",
    "            'waste of money',\n",
    "            'pathetic picture',\n",
    "            'It was very boring',\n",
    "            'I did not like the movie',\n",
    "            'The movie was horrible',\n",
    "            'I will not recommend',\n",
    "            'The acting is pathetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is an excellent movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The move was fantastic I like it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You should watch it is brilliant</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            comment    review\n",
       "0        This is an excellent movie  positive\n",
       "1  The move was fantastic I like it  positive\n",
       "2  You should watch it is brilliant  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [(pr,\"positive\") for pr in positive] + [(nr,\"negative\") for nr in negative]\n",
    "\n",
    "data = pd.DataFrame(reviews,columns=[\"comment\",'review'])\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the DataFrame rows\n",
    "data = data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>It was very boring</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The acting is pathetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I did not like the movie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You should watch it is brilliant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonderfully directed and executed I like it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment  review\n",
       "11                           It was very boring       0\n",
       "15                       The acting is pathetic       0\n",
       "12                     I did not like the movie       0\n",
       "2              You should watch it is brilliant       1\n",
       "4   Wonderfully directed and executed I like it       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "data['review'] = lb_make.fit_transform(data[\"review\"])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower the text\n",
    "data['comment'] = data['comment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find max_length sequence\n",
    "\n",
    "max_seq_len = max([len([y for y in x.split()]) for x in data['comment']])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of samples = \n",
    "\n",
    "num_samples = data.shape[0]\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(data['comment'])\n",
    "word2id = tokenizer.word_index\n",
    "\n",
    "word2id['PAD'] = 0\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in data['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(id2word)\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  6, 14, 15,  0,  0,  0],\n",
       "       [ 3,  9,  4, 10,  0,  0,  0],\n",
       "       [ 5, 16, 11,  7,  3,  2,  0],\n",
       "       [17, 18, 19,  1,  4, 20,  0],\n",
       "       [21, 22, 23, 24,  5,  7,  1],\n",
       "       [10, 25,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  8, 26,  2,  0,  0],\n",
       "       [27, 28, 29,  0,  0,  0,  0],\n",
       "       [ 3, 30,  6, 12,  5,  7,  1],\n",
       "       [ 5, 31, 11, 32,  0,  0,  0],\n",
       "       [13,  9,  0,  0,  0,  0,  0],\n",
       "       [33, 34,  0,  0,  0,  0,  0],\n",
       "       [35, 36, 37,  8, 38,  2,  0],\n",
       "       [39,  4, 40, 41,  2,  0,  0],\n",
       "       [ 3,  2,  6, 13,  0,  0,  0],\n",
       "       [42,  8, 12, 43,  0,  0,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_inputs = pad_sequences(wids,padding='post')\n",
    "\n",
    "padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = data['review'].values # output labels\n",
    "\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=7, activation='relu')) \n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "#model.fit(pad_sequences, sentiments, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 2.5637 - accuracy: 0.4284\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.8848 - accuracy: 0.6081\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.6380\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6341\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.6576\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6380\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6289\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6484\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6589\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6589\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6602\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6758\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6745\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6771\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6693\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6823\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6771\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6732\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6706\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.6771\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6797\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.6992\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.6888\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.6979\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6953\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6940\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6901\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.6992\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6901\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7096\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.6823\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6927\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6940\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6771\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6966\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7005\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7044\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7109\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7005\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.6927\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.6914\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7005\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7161\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7057\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7070\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7070\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7188\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7174\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7174\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7122\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7148\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7044\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7044\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7305\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7266\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.7331\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7174\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7240\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7370\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7253\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7318\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7253\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7201\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7435\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.7422\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.7370\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.7188\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7435\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7409\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7279\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7370\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7240\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7474\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7474\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7292\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7435\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7396\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.7487\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7448\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7487\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7279\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.7396\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7461\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7513\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7487\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7292\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7435\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7474\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7487\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7565\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.7513\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7500\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7513\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7565\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7526\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7513\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7591\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7760\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7643\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7591\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7487\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7565\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7604\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7565\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7643\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7604\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7643\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7396\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7552\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7682\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7578\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7604\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7448\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7604\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7578\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7409\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7487\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7487\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7604\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7708\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7656\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7591\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7695\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7591\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7656\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7591\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7617\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7617\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7487\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7695\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7734\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7656\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7734\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7734\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7708\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7591\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7812\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7591\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7708\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7760\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7734\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7539\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7643\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7669\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7682\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7682\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7760\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7773\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7708\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7669\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7669\n",
      "Accuracy: 76.69\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "dataset = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "X = dataset.iloc[:,:-1] # 8 Features\n",
    "y = dataset['Outcome']\n",
    "\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.7983 - accuracy: 0.5625\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - 0s 352us/step - loss: 1.7232 - accuracy: 0.5625\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - 0s 418us/step - loss: 1.6363 - accuracy: 0.5625\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - 0s 262us/step - loss: 1.5509 - accuracy: 0.5625\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - 0s 232us/step - loss: 1.4639 - accuracy: 0.5625\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - 0s 222us/step - loss: 1.4019 - accuracy: 0.5625\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - 0s 334us/step - loss: 1.3422 - accuracy: 0.6250\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - 0s 357us/step - loss: 1.2663 - accuracy: 0.6875\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - 0s 285us/step - loss: 1.2171 - accuracy: 0.6875\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - 0s 410us/step - loss: 1.1333 - accuracy: 0.6875\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - 0s 338us/step - loss: 1.0862 - accuracy: 0.6875\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - 0s 341us/step - loss: 1.0437 - accuracy: 0.6875\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - 0s 249us/step - loss: 0.9928 - accuracy: 0.6250\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - 0s 292us/step - loss: 0.9404 - accuracy: 0.6250\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - 0s 252us/step - loss: 0.9157 - accuracy: 0.6250\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - 0s 277us/step - loss: 0.8814 - accuracy: 0.6250\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - 0s 364us/step - loss: 0.8505 - accuracy: 0.6250\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - 0s 406us/step - loss: 0.8240 - accuracy: 0.6250\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - 0s 260us/step - loss: 0.8121 - accuracy: 0.6250\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - 0s 431us/step - loss: 0.7907 - accuracy: 0.6250\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - 0s 337us/step - loss: 0.7701 - accuracy: 0.6250\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - 0s 260us/step - loss: 0.7526 - accuracy: 0.6250\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - 0s 252us/step - loss: 0.7413 - accuracy: 0.6250\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - 0s 242us/step - loss: 0.7168 - accuracy: 0.6250\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - 0s 301us/step - loss: 0.6984 - accuracy: 0.6250\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - 0s 310us/step - loss: 0.6809 - accuracy: 0.6250\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - 0s 307us/step - loss: 0.6649 - accuracy: 0.6250\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - 0s 272us/step - loss: 0.6490 - accuracy: 0.6250\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - 0s 422us/step - loss: 0.6279 - accuracy: 0.6250\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - 0s 230us/step - loss: 0.6146 - accuracy: 0.6250\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - 0s 321us/step - loss: 0.6027 - accuracy: 0.6250\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.5862 - accuracy: 0.6250\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - 0s 374us/step - loss: 0.5779 - accuracy: 0.6250\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - 0s 278us/step - loss: 0.5675 - accuracy: 0.6250\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - 0s 324us/step - loss: 0.5555 - accuracy: 0.6875\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - 0s 287us/step - loss: 0.5488 - accuracy: 0.6875\n",
      "Epoch 37/150\n",
      "16/16 [==============================] - 0s 307us/step - loss: 0.5370 - accuracy: 0.6875\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - 0s 343us/step - loss: 0.5299 - accuracy: 0.6875\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - 0s 284us/step - loss: 0.5203 - accuracy: 0.6875\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - 0s 352us/step - loss: 0.5132 - accuracy: 0.6875\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - 0s 306us/step - loss: 0.5065 - accuracy: 0.6875\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - 0s 275us/step - loss: 0.4986 - accuracy: 0.6875\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - 0s 376us/step - loss: 0.4920 - accuracy: 0.6875\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.4862 - accuracy: 0.7500\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - 0s 299us/step - loss: 0.4802 - accuracy: 0.7500\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - 0s 397us/step - loss: 0.4740 - accuracy: 0.7500\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - 0s 290us/step - loss: 0.4674 - accuracy: 0.7500\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - 0s 357us/step - loss: 0.4622 - accuracy: 0.7500\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - 0s 321us/step - loss: 0.4573 - accuracy: 0.7500\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - 0s 341us/step - loss: 0.4513 - accuracy: 0.7500\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - 0s 344us/step - loss: 0.4459 - accuracy: 0.7500\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - 0s 307us/step - loss: 0.4406 - accuracy: 0.7500\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - 0s 291us/step - loss: 0.4353 - accuracy: 0.8125\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - 0s 333us/step - loss: 0.4308 - accuracy: 0.8125\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - 0s 343us/step - loss: 0.4255 - accuracy: 0.8125\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - 0s 287us/step - loss: 0.4205 - accuracy: 0.8125\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - 0s 328us/step - loss: 0.4168 - accuracy: 0.8125\n",
      "Epoch 58/150\n",
      "16/16 [==============================] - 0s 339us/step - loss: 0.4126 - accuracy: 0.8125\n",
      "Epoch 59/150\n",
      "16/16 [==============================] - 0s 422us/step - loss: 0.4075 - accuracy: 0.8125\n",
      "Epoch 60/150\n",
      "16/16 [==============================] - 0s 484us/step - loss: 0.4037 - accuracy: 0.8125\n",
      "Epoch 61/150\n",
      "16/16 [==============================] - 0s 461us/step - loss: 0.3996 - accuracy: 0.8125\n",
      "Epoch 62/150\n",
      "16/16 [==============================] - 0s 409us/step - loss: 0.3950 - accuracy: 0.8125\n",
      "Epoch 63/150\n",
      "16/16 [==============================] - 0s 376us/step - loss: 0.3914 - accuracy: 0.8125\n",
      "Epoch 64/150\n",
      "16/16 [==============================] - 0s 306us/step - loss: 0.3877 - accuracy: 0.8125\n",
      "Epoch 65/150\n",
      "16/16 [==============================] - 0s 338us/step - loss: 0.3832 - accuracy: 0.8125\n",
      "Epoch 66/150\n",
      "16/16 [==============================] - 0s 465us/step - loss: 0.3798 - accuracy: 0.8125\n",
      "Epoch 67/150\n",
      "16/16 [==============================] - 0s 358us/step - loss: 0.3761 - accuracy: 0.8125\n",
      "Epoch 68/150\n",
      "16/16 [==============================] - 0s 294us/step - loss: 0.3720 - accuracy: 0.8125\n",
      "Epoch 69/150\n",
      "16/16 [==============================] - 0s 370us/step - loss: 0.3678 - accuracy: 0.8125\n",
      "Epoch 70/150\n",
      "16/16 [==============================] - 0s 383us/step - loss: 0.3649 - accuracy: 0.8750\n",
      "Epoch 71/150\n",
      "16/16 [==============================] - 0s 406us/step - loss: 0.3612 - accuracy: 0.8750\n",
      "Epoch 72/150\n",
      "16/16 [==============================] - 0s 479us/step - loss: 0.3572 - accuracy: 0.8750\n",
      "Epoch 73/150\n",
      "16/16 [==============================] - 0s 355us/step - loss: 0.3550 - accuracy: 0.8750\n",
      "Epoch 74/150\n",
      "16/16 [==============================] - 0s 389us/step - loss: 0.3508 - accuracy: 0.8750\n",
      "Epoch 75/150\n",
      "16/16 [==============================] - 0s 419us/step - loss: 0.3477 - accuracy: 0.8750\n",
      "Epoch 76/150\n",
      "16/16 [==============================] - 0s 325us/step - loss: 0.3437 - accuracy: 0.8750\n",
      "Epoch 77/150\n",
      "16/16 [==============================] - 0s 450us/step - loss: 0.3405 - accuracy: 0.8750\n",
      "Epoch 78/150\n",
      "16/16 [==============================] - 0s 350us/step - loss: 0.3379 - accuracy: 0.8750\n",
      "Epoch 79/150\n",
      "16/16 [==============================] - 0s 314us/step - loss: 0.3346 - accuracy: 0.8750\n",
      "Epoch 80/150\n",
      "16/16 [==============================] - 0s 162us/step - loss: 0.3310 - accuracy: 0.8750\n",
      "Epoch 81/150\n",
      "16/16 [==============================] - 0s 452us/step - loss: 0.3285 - accuracy: 0.8750\n",
      "Epoch 82/150\n",
      "16/16 [==============================] - 0s 381us/step - loss: 0.3258 - accuracy: 0.8750\n",
      "Epoch 83/150\n",
      "16/16 [==============================] - 0s 214us/step - loss: 0.3225 - accuracy: 0.8750\n",
      "Epoch 84/150\n",
      "16/16 [==============================] - 0s 748us/step - loss: 0.3202 - accuracy: 0.8750\n",
      "Epoch 85/150\n",
      "16/16 [==============================] - 0s 326us/step - loss: 0.3174 - accuracy: 0.8750\n",
      "Epoch 86/150\n",
      "16/16 [==============================] - 0s 450us/step - loss: 0.3151 - accuracy: 0.8750\n",
      "Epoch 87/150\n",
      "16/16 [==============================] - 0s 300us/step - loss: 0.3126 - accuracy: 0.8750\n",
      "Epoch 88/150\n",
      "16/16 [==============================] - 0s 425us/step - loss: 0.3107 - accuracy: 0.8750\n",
      "Epoch 89/150\n",
      "16/16 [==============================] - 0s 509us/step - loss: 0.3084 - accuracy: 0.8750\n",
      "Epoch 90/150\n",
      "16/16 [==============================] - 0s 279us/step - loss: 0.3061 - accuracy: 0.8750\n",
      "Epoch 91/150\n",
      "16/16 [==============================] - 0s 542us/step - loss: 0.3037 - accuracy: 0.8750\n",
      "Epoch 92/150\n",
      "16/16 [==============================] - 0s 416us/step - loss: 0.3015 - accuracy: 0.8750\n",
      "Epoch 93/150\n",
      "16/16 [==============================] - 0s 403us/step - loss: 0.3001 - accuracy: 0.8750\n",
      "Epoch 94/150\n",
      "16/16 [==============================] - 0s 445us/step - loss: 0.2975 - accuracy: 0.8750\n",
      "Epoch 95/150\n",
      "16/16 [==============================] - 0s 438us/step - loss: 0.2955 - accuracy: 0.8750\n",
      "Epoch 96/150\n",
      "16/16 [==============================] - 0s 314us/step - loss: 0.2935 - accuracy: 0.8750\n",
      "Epoch 97/150\n",
      "16/16 [==============================] - 0s 501us/step - loss: 0.2915 - accuracy: 0.8750\n",
      "Epoch 98/150\n",
      "16/16 [==============================] - 0s 427us/step - loss: 0.2898 - accuracy: 0.9375\n",
      "Epoch 99/150\n",
      "16/16 [==============================] - 0s 352us/step - loss: 0.2875 - accuracy: 0.9375\n",
      "Epoch 100/150\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2858 - accuracy: 0.9375\n",
      "Epoch 101/150\n",
      "16/16 [==============================] - 0s 497us/step - loss: 0.2838 - accuracy: 0.9375\n",
      "Epoch 102/150\n",
      "16/16 [==============================] - 0s 370us/step - loss: 0.2821 - accuracy: 0.9375\n",
      "Epoch 103/150\n",
      "16/16 [==============================] - 0s 229us/step - loss: 0.2803 - accuracy: 0.9375\n",
      "Epoch 104/150\n",
      "16/16 [==============================] - 0s 504us/step - loss: 0.2786 - accuracy: 0.9375\n",
      "Epoch 105/150\n",
      "16/16 [==============================] - 0s 251us/step - loss: 0.2772 - accuracy: 0.9375\n",
      "Epoch 106/150\n",
      "16/16 [==============================] - 0s 482us/step - loss: 0.2752 - accuracy: 0.9375\n",
      "Epoch 107/150\n",
      "16/16 [==============================] - 0s 501us/step - loss: 0.2736 - accuracy: 0.9375\n",
      "Epoch 108/150\n",
      "16/16 [==============================] - 0s 491us/step - loss: 0.2722 - accuracy: 0.9375\n",
      "Epoch 109/150\n",
      "16/16 [==============================] - 0s 494us/step - loss: 0.2708 - accuracy: 0.9375\n",
      "Epoch 110/150\n",
      "16/16 [==============================] - 0s 433us/step - loss: 0.2686 - accuracy: 0.9375\n",
      "Epoch 111/150\n",
      "16/16 [==============================] - 0s 452us/step - loss: 0.2672 - accuracy: 0.9375\n",
      "Epoch 112/150\n",
      "16/16 [==============================] - 0s 460us/step - loss: 0.2652 - accuracy: 0.9375\n",
      "Epoch 113/150\n",
      "16/16 [==============================] - 0s 292us/step - loss: 0.2639 - accuracy: 0.9375\n",
      "Epoch 114/150\n",
      "16/16 [==============================] - 0s 510us/step - loss: 0.2625 - accuracy: 0.9375\n",
      "Epoch 115/150\n",
      "16/16 [==============================] - 0s 400us/step - loss: 0.2607 - accuracy: 0.9375\n",
      "Epoch 116/150\n",
      "16/16 [==============================] - 0s 858us/step - loss: 0.2591 - accuracy: 0.9375\n",
      "Epoch 117/150\n",
      "16/16 [==============================] - 0s 508us/step - loss: 0.2582 - accuracy: 0.9375\n",
      "Epoch 118/150\n",
      "16/16 [==============================] - 0s 439us/step - loss: 0.2565 - accuracy: 0.9375\n",
      "Epoch 119/150\n",
      "16/16 [==============================] - 0s 482us/step - loss: 0.2554 - accuracy: 0.9375\n",
      "Epoch 120/150\n",
      "16/16 [==============================] - 0s 727us/step - loss: 0.2540 - accuracy: 0.9375\n",
      "Epoch 121/150\n",
      "16/16 [==============================] - 0s 0us/step - loss: 0.2531 - accuracy: 0.9375\n",
      "Epoch 122/150\n",
      "16/16 [==============================] - 0s 374us/step - loss: 0.2515 - accuracy: 0.9375\n",
      "Epoch 123/150\n",
      "16/16 [==============================] - 0s 579us/step - loss: 0.2504 - accuracy: 0.9375\n",
      "Epoch 124/150\n",
      "16/16 [==============================] - 0s 220us/step - loss: 0.2490 - accuracy: 0.9375\n",
      "Epoch 125/150\n",
      "16/16 [==============================] - 0s 773us/step - loss: 0.2478 - accuracy: 0.9375\n",
      "Epoch 126/150\n",
      "16/16 [==============================] - 0s 383us/step - loss: 0.2463 - accuracy: 0.9375\n",
      "Epoch 127/150\n",
      "16/16 [==============================] - 0s 268us/step - loss: 0.2453 - accuracy: 0.9375\n",
      "Epoch 128/150\n",
      "16/16 [==============================] - 0s 263us/step - loss: 0.2443 - accuracy: 0.9375\n",
      "Epoch 129/150\n",
      "16/16 [==============================] - 0s 264us/step - loss: 0.2429 - accuracy: 0.9375\n",
      "Epoch 130/150\n",
      "16/16 [==============================] - 0s 129us/step - loss: 0.2418 - accuracy: 0.9375\n",
      "Epoch 131/150\n",
      "16/16 [==============================] - 0s 283us/step - loss: 0.2409 - accuracy: 0.9375\n",
      "Epoch 132/150\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.2398 - accuracy: 0.9375\n",
      "Epoch 133/150\n",
      "16/16 [==============================] - 0s 240us/step - loss: 0.2386 - accuracy: 0.9375\n",
      "Epoch 134/150\n",
      "16/16 [==============================] - 0s 252us/step - loss: 0.2373 - accuracy: 0.9375\n",
      "Epoch 135/150\n",
      "16/16 [==============================] - 0s 298us/step - loss: 0.2365 - accuracy: 0.9375\n",
      "Epoch 136/150\n",
      "16/16 [==============================] - 0s 361us/step - loss: 0.2352 - accuracy: 0.9375\n",
      "Epoch 137/150\n",
      "16/16 [==============================] - 0s 333us/step - loss: 0.2341 - accuracy: 0.9375\n",
      "Epoch 138/150\n",
      "16/16 [==============================] - 0s 857us/step - loss: 0.2332 - accuracy: 0.9375\n",
      "Epoch 139/150\n",
      "16/16 [==============================] - 0s 539us/step - loss: 0.2322 - accuracy: 0.9375\n",
      "Epoch 140/150\n",
      "16/16 [==============================] - 0s 260us/step - loss: 0.2310 - accuracy: 0.9375\n",
      "Epoch 141/150\n",
      "16/16 [==============================] - 0s 350us/step - loss: 0.2299 - accuracy: 0.9375\n",
      "Epoch 142/150\n",
      "16/16 [==============================] - 0s 305us/step - loss: 0.2286 - accuracy: 0.9375\n",
      "Epoch 143/150\n",
      "16/16 [==============================] - 0s 371us/step - loss: 0.2278 - accuracy: 0.9375\n",
      "Epoch 144/150\n",
      "16/16 [==============================] - 0s 569us/step - loss: 0.2266 - accuracy: 0.9375\n",
      "Epoch 145/150\n",
      "16/16 [==============================] - 0s 373us/step - loss: 0.2260 - accuracy: 0.9375\n",
      "Epoch 146/150\n",
      "16/16 [==============================] - 0s 278us/step - loss: 0.2248 - accuracy: 0.9375\n",
      "Epoch 147/150\n",
      "16/16 [==============================] - 0s 221us/step - loss: 0.2237 - accuracy: 0.9375\n",
      "Epoch 148/150\n",
      "16/16 [==============================] - 0s 965us/step - loss: 0.2227 - accuracy: 0.9375\n",
      "Epoch 149/150\n",
      "16/16 [==============================] - 0s 358us/step - loss: 0.2220 - accuracy: 0.9375\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 0s 295us/step - loss: 0.2208 - accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x130173f3648>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=7, activation='relu')) # 7 Features\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(padded_inputs, sentiments, epochs=150, batch_size=10)\n",
    "# evaluate the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  6, 14, 15,  0,  0,  0],\n",
       "       [ 3,  9,  4, 10,  0,  0,  0],\n",
       "       [ 5, 16, 11,  7,  3,  2,  0],\n",
       "       [17, 18, 19,  1,  4, 20,  0],\n",
       "       [21, 22, 23, 24,  5,  7,  1],\n",
       "       [10, 25,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  8, 26,  2,  0,  0],\n",
       "       [27, 28, 29,  0,  0,  0,  0],\n",
       "       [ 3, 30,  6, 12,  5,  7,  1],\n",
       "       [ 5, 31, 11, 32,  0,  0,  0],\n",
       "       [13,  9,  0,  0,  0,  0,  0],\n",
       "       [33, 34,  0,  0,  0,  0,  0],\n",
       "       [35, 36, 37,  8, 38,  2,  0],\n",
       "       [39,  4, 40, 41,  2,  0,  0],\n",
       "       [ 3,  2,  6, 13,  0,  0,  0],\n",
       "       [42,  8, 12, 43,  0,  0,  0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input = np.array([[ 1,  6, 14, 15,  0,  0,  0]]).reshape(1,7)\n",
    "\n",
    "\n",
    "model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
